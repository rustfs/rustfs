# RustFS å…ƒæ•°æ®ä¸­å¿ƒå¤šå‰¯æœ¬æ¶æ„è®¾è®¡

**ç‰ˆæœ¬**: 1.0  
**æ—¥æœŸ**: 2026-02-24  
**ä½œè€…**: RustFS Architecture Team  
**çŠ¶æ€**: Design Proposal

---

## ç›®å½•

1. [æ‰§è¡Œæ‘˜è¦](#æ‰§è¡Œæ‘˜è¦)
2. [æ¶æ„æ¦‚è¿°](#æ¶æ„æ¦‚è¿°)
3. [æ ¸å¿ƒè®¾è®¡åŸåˆ™](#æ ¸å¿ƒè®¾è®¡åŸåˆ™)
4. [å¤šå‰¯æœ¬æ¶æ„](#å¤šå‰¯æœ¬æ¶æ„)
5. [ä¸€è‡´æ€§æ¨¡å‹](#ä¸€è‡´æ€§æ¨¡å‹)
6. [å¤åˆ¶åè®®](#å¤åˆ¶åè®®)
7. [æ•…éšœå¤„ç†](#æ•…éšœå¤„ç†)
8. [å®ç°æ–¹æ¡ˆ](#å®ç°æ–¹æ¡ˆ)
9. [æ€§èƒ½ä¼˜åŒ–](#æ€§èƒ½ä¼˜åŒ–)
10. [è¿ç»´ç®¡ç†](#è¿ç»´ç®¡ç†)

---

## æ‰§è¡Œæ‘˜è¦

æœ¬æ–‡æ¡£æè¿°å¦‚ä½•ä¸º RustFS çš„é«˜æ€§èƒ½ KV å…ƒæ•°æ®ä¸­å¿ƒï¼ˆSurrealKV + Ferntree + SurrealMXï¼‰è®¾è®¡å¤šå‰¯æœ¬æ”¯æŒï¼Œä»¥å®ç°ï¼š

- âœ… **é«˜å¯ç”¨æ€§**: å¤šå‰¯æœ¬å®¹é”™ï¼Œè‡ªåŠ¨æ•…éšœè½¬ç§»
- âœ… **æ•°æ®æŒä¹…æ€§**: å¤šèŠ‚ç‚¹æ•°æ®å†—ä½™
- âœ… **è¯»æ€§èƒ½æ‰©å±•**: å‰¯æœ¬åˆ†æ‹…è¯»è´Ÿè½½
- âœ… **ä¸€è‡´æ€§ä¿è¯**: å¼ºä¸€è‡´æ€§æˆ–æœ€ç»ˆä¸€è‡´æ€§å¯é€‰

### å…³é”®æŒ‡æ ‡

| æŒ‡æ ‡     | ç›®æ ‡å€¼     | è¯´æ˜           |
|--------|---------|--------------|
| å‰¯æœ¬æ•°é‡   | 3-5     | å¯é…ç½®ï¼Œæ¨è 3 å‰¯æœ¬  |
| å†™å…¥å»¶è¿Ÿ   | < 10ms  | ä¸»èŠ‚ç‚¹ç¡®è®¤ + å¼‚æ­¥å¤åˆ¶ |
| ä¸€è‡´æ€§çº§åˆ«  | å¼ºä¸€è‡´æ€§    | Raft å…±è¯†åè®®    |
| æ•…éšœè½¬ç§»æ—¶é—´ | < 30s   | è‡ªåŠ¨é€‰ä¸» + çŠ¶æ€æ¢å¤  |
| æ•°æ®åŒæ­¥å»¶è¿Ÿ | < 100ms | å‰¯æœ¬é—´æ•°æ®åŒæ­¥      |

### è®¾è®¡ç›®æ ‡

1. **ä¿æŒå•æœºæ€§èƒ½**: ä¸é™ä½ç°æœ‰å…ƒæ•°æ®å¼•æ“çš„æ€§èƒ½
2. **é€æ˜å¤åˆ¶**: å¯¹ä¸Šå±‚åº”ç”¨é€æ˜ï¼Œæ— éœ€ä¿®æ”¹ API
3. **æ¸è¿›å¼è¿ç§»**: æ”¯æŒä»å•èŠ‚ç‚¹å¹³æ»‘å‡çº§åˆ°å¤šèŠ‚ç‚¹
4. **æ¨¡å—åŒ–è®¾è®¡**: å¤åˆ¶å±‚ä¸å­˜å‚¨å±‚è§£è€¦

---

## æ¶æ„æ¦‚è¿°

### å½“å‰æ¶æ„ (å•èŠ‚ç‚¹)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  S3 Application Layer                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              LocalMetadataEngine                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  SurrealKV   â”‚  â”‚  Ferntree   â”‚  â”‚   SurrealMX    â”‚ â”‚
â”‚  â”‚   (ACID)     â”‚  â”‚  (B+ Tree)  â”‚  â”‚   (Storage)    â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
                  Local File System
```

**é—®é¢˜**:

- âŒ å•ç‚¹æ•…éšœï¼ˆSPOFï¼‰
- âŒ æ— æ•°æ®å†—ä½™
- âŒ æ— æ³•æ°´å¹³æ‰©å±•è¯»èƒ½åŠ›

### å¤šå‰¯æœ¬æ¶æ„ (ç›®æ ‡)

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚     S3 Application Layer          â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ReplicatedMetadataEngine                   â”‚
â”‚                  (Raft Consensus + Replication)               â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                      â”‚                      â”‚
       â–¼                      â–¼                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Node 1        â”‚  â”‚   Node 2        â”‚  â”‚   Node 3        â”‚
â”‚   (Leader)      â”‚  â”‚   (Follower)    â”‚  â”‚   (Follower)    â”‚
â”‚                 â”‚  â”‚                 â”‚  â”‚                 â”‚
â”‚ LocalMetadata   â”‚  â”‚ LocalMetadata   â”‚  â”‚ LocalMetadata   â”‚
â”‚ Engine          â”‚  â”‚ Engine          â”‚  â”‚ Engine          â”‚
â”‚  â”œâ”€SurrealKV    â”‚  â”‚  â”œâ”€SurrealKV    â”‚  â”‚  â”œâ”€SurrealKV    â”‚
â”‚  â”œâ”€Ferntree     â”‚  â”‚  â”œâ”€Ferntree     â”‚  â”‚  â”œâ”€Ferntree     â”‚
â”‚  â””â”€SurrealMX    â”‚  â”‚  â””â”€SurrealMX    â”‚  â”‚  â””â”€SurrealMX    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                      â”‚                      â”‚
       â–¼                      â–¼                      â–¼
   Local FS             Local FS             Local FS
```

**ä¼˜åŠ¿**:

- âœ… é«˜å¯ç”¨ï¼šä»»æ„èŠ‚ç‚¹æ•…éšœä¸å½±å“æœåŠ¡
- âœ… æ•°æ®å†—ä½™ï¼šå¤šå‰¯æœ¬ä¿è¯æ•°æ®æŒä¹…æ€§
- âœ… è¯»æ‰©å±•ï¼šå‰¯æœ¬åˆ†æ‹…è¯»è´Ÿè½½
- âœ… ä¸€è‡´æ€§ï¼šRaft ä¿è¯å¼ºä¸€è‡´æ€§

---

## æ ¸å¿ƒè®¾è®¡åŸåˆ™

### 1. åˆ†å±‚è®¾è®¡

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 4: Application API                               â”‚
â”‚  (S3 Compatible Interface)                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 3: Replication Coordination                      â”‚
â”‚  (Raft Consensus + Request Routing)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 2: Metadata Engine                               â”‚
â”‚  (LocalMetadataEngine - Existing)                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 1: Storage Backends                              â”‚
â”‚  (SurrealKV + Ferntree + SurrealMX)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**å…³é”®ç‚¹**:

- Layer 1-2: ä¿æŒä¸å˜ï¼ˆç°æœ‰å…ƒæ•°æ®å¼•æ“ï¼‰
- Layer 3: æ–°å¢å¤åˆ¶åè°ƒå±‚
- Layer 4: API ä¿æŒå…¼å®¹

### 2. å¤åˆ¶å•å…ƒ

å…ƒæ•°æ®å¤åˆ¶ä»¥ **äº‹åŠ¡ï¼ˆTransactionï¼‰** ä¸ºå•ä½ï¼š

```rust
pub struct MetadataOperation {
    op_id: u64,                    // æ“ä½œ IDï¼ˆå•è°ƒé€’å¢ï¼‰
    op_type: OperationType,        // æ“ä½œç±»å‹
    timestamp: i64,                // æ—¶é—´æˆ³
    data: Vec<u8>,                 // åºåˆ—åŒ–çš„æ“ä½œæ•°æ®
}

pub enum OperationType {
    PutObject,      // åˆ›å»º/æ›´æ–°å¯¹è±¡
    DeleteObject,   // åˆ é™¤å¯¹è±¡
    UpdateMetadata, // æ›´æ–°å…ƒæ•°æ®
    BatchOps,       // æ‰¹é‡æ“ä½œ
}
```

### 3. ä¸€è‡´æ€§çº§åˆ«

æ”¯æŒä¸¤ç§ä¸€è‡´æ€§æ¨¡å‹ï¼Œå¯é…ç½®ï¼š

| çº§åˆ«        | å†™å…¥ç¡®è®¤æ¡ä»¶ | è¯»å–ä¿è¯ | æ€§èƒ½ | é€‚ç”¨åœºæ™¯    |
|-----------|--------|------|----|---------|
| **å¼ºä¸€è‡´æ€§**  | å¤šæ•°å‰¯æœ¬ç¡®è®¤ | æœ€æ–°æ•°æ® | ä¸­  | é‡‘èã€å…³é”®ä¸šåŠ¡ |
| **æœ€ç»ˆä¸€è‡´æ€§** | ä¸»å‰¯æœ¬ç¡®è®¤  | å¯èƒ½æ»å | é«˜  | æ—¥å¿—ã€ç›‘æ§æ•°æ® |

**æ¨èé…ç½®**: é»˜è®¤ä½¿ç”¨å¼ºä¸€è‡´æ€§ï¼Œå…³é”®å…ƒæ•°æ®ä¸å¯å¦¥åã€‚

---

## å¤šå‰¯æœ¬æ¶æ„

### 1. æ ¸å¿ƒç»„ä»¶

#### 1.1 ReplicatedMetadataEngine

å¤åˆ¶åè°ƒçš„é¡¶å±‚æ¥å£ï¼š

```rust
/// ReplicatedMetadataEngine wraps LocalMetadataEngine with replication support.
pub struct ReplicatedMetadataEngine {
    /// Local metadata engine (existing)
    local_engine: Arc<LocalMetadataEngine>,

    /// Raft node for consensus
    raft_node: Arc<RaftNode>,

    /// Replication manager
    replication_manager: Arc<ReplicationManager>,

    /// Configuration
    config: ReplicationConfig,
}

#[async_trait]
impl MetadataEngine for ReplicatedMetadataEngine {
    async fn put_object(...) -> Result<ObjectInfo> {
        // 1. Serialize operation
        let op = MetadataOperation::new(OperationType::PutObject, ...);

        // 2. Propose to Raft
        self.raft_node.propose(op).await?;

        // 3. Wait for commit (majority)
        let result = self.raft_node.wait_committed(op.op_id).await?;

        // 4. Apply to local engine
        self.local_engine.put_object(...).await
    }

    async fn get_object_reader(...) -> Result<GetObjectReader> {
        // Read from local replica (no consensus needed)
        self.local_engine.get_object_reader(...).await
    }

    // ... other methods
}
```

#### 1.2 RaftNode

åŸºäº Raft å…±è¯†åè®®çš„èŠ‚ç‚¹å®ç°ï¼š

```rust
use raft::{Config, Node, Storage, RawNode};
use raft::prelude::*;

pub struct RaftNode {
    /// Raft raw node
    raw_node: Arc<Mutex<RawNode<MemStorage>>>,

    /// Node ID
    node_id: u64,

    /// Peer addresses
    peers: HashMap<u64, String>,

    /// Applied operation index
    applied_index: AtomicU64,

    /// Operation log
    op_log: Arc<RwLock<VecDeque<MetadataOperation>>>,

    /// Commit notifier
    commit_notifier: Arc<Notify>,
}

impl RaftNode {
    /// Propose an operation to the Raft cluster
    pub async fn propose(&self, op: MetadataOperation) -> Result<()> {
        let data = serde_json::to_vec(&op)?;

        let mut raw_node = self.raw_node.lock().await;
        raw_node.propose(vec![], data)?;

        Ok(())
    }

    /// Wait for an operation to be committed
    pub async fn wait_committed(&self, op_id: u64) -> Result<()> {
        loop {
            if self.applied_index.load(Ordering::SeqCst) >= op_id {
                return Ok(());
            }

            // Wait for commit notification
            self.commit_notifier.notified().await;
        }
    }

    /// Process Raft ready state
    pub async fn process_ready(&self, local_engine: &LocalMetadataEngine) -> Result<()> {
        let mut raw_node = self.raw_node.lock().await;

        if !raw_node.has_ready() {
            return Ok(());
        }

        let mut ready = raw_node.ready();

        // Send messages to peers
        for msg in ready.take_messages() {
            self.send_to_peer(msg).await?;
        }

        // Apply committed entries
        for entry in ready.take_committed_entries() {
            if entry.data.is_empty() {
                continue;
            }

            let op: MetadataOperation = serde_json::from_slice(&entry.data)?;

            // Apply to local engine
            self.apply_operation(local_engine, op).await?;

            // Update applied index
            self.applied_index.store(entry.index, Ordering::SeqCst);
        }

        // Persist snapshot
        if !ready.snapshot().is_empty() {
            self.save_snapshot(ready.snapshot()).await?;
        }

        // Advance Raft
        let mut light_rd = raw_node.advance(ready);

        // Apply updates
        if let Some(commit) = light_rd.commit_index() {
            // Notify waiters
            self.commit_notifier.notify_waiters();
        }

        Ok(())
    }

    /// Apply operation to local engine
    async fn apply_operation(
        &self,
        engine: &LocalMetadataEngine,
        op: MetadataOperation,
    ) -> Result<()> {
        match op.op_type {
            OperationType::PutObject => {
                // Deserialize and apply
                let put_req: PutObjectRequest = serde_json::from_slice(&op.data)?;
                engine.put_object(
                    &put_req.bucket,
                    &put_req.key,
                    Box::new(Cursor::new(put_req.data)),
                    put_req.size,
                    put_req.opts,
                ).await?;
            }
            OperationType::DeleteObject => {
                let del_req: DeleteObjectRequest = serde_json::from_slice(&op.data)?;
                engine.delete_object(&del_req.bucket, &del_req.key).await?;
            }
            // ... handle other operations
            _ => {}
        }

        Ok(())
    }
}
```

#### 1.3 ReplicationManager

ç®¡ç†å‰¯æœ¬åŒæ­¥å’Œå¥åº·æ£€æŸ¥ï¼š

```rust
pub struct ReplicationManager {
    /// Local node ID
    node_id: u64,

    /// Peer connections
    peers: Arc<RwLock<HashMap<u64, PeerConnection>>>,

    /// Replication state
    state: Arc<RwLock<ReplicationState>>,

    /// Health checker
    health_checker: Arc<HealthChecker>,
}

pub struct PeerConnection {
    node_id: u64,
    address: String,
    client: ReplicationClient,
    last_heartbeat: AtomicI64,
    status: Arc<RwLock<PeerStatus>>,
}

pub enum PeerStatus {
    Healthy,
    Lagging { behind: u64 },
    Unreachable,
    Failed,
}

impl ReplicationManager {
    /// Start replication manager
    pub async fn start(&self, raft_node: Arc<RaftNode>) {
        // Background task: process Raft ready
        tokio::spawn(Self::raft_ready_loop(raft_node.clone()));

        // Background task: health check
        tokio::spawn(Self::health_check_loop(self.health_checker.clone()));

        // Background task: catch-up lagging replicas
        tokio::spawn(Self::catchup_loop(self.clone()));
    }

    async fn raft_ready_loop(raft_node: Arc<RaftNode>) {
        let mut interval = tokio::time::interval(Duration::from_millis(10));

        loop {
            interval.tick().await;

            if let Err(e) = raft_node.process_ready(&local_engine).await {
                error!("Failed to process Raft ready: {}", e);
            }
        }
    }

    async fn health_check_loop(health_checker: Arc<HealthChecker>) {
        let mut interval = tokio::time::interval(Duration::from_secs(1));

        loop {
            interval.tick().await;
            health_checker.check_all_peers().await;
        }
    }
}
```

### 2. æ•°æ®æµ

#### 2.1 å†™å…¥æµç¨‹ (Put Object)

```
Client
  â”‚
  â”‚ 1. PUT /bucket/key
  â–¼
ReplicatedMetadataEngine (Leader)
  â”‚
  â”‚ 2. Create MetadataOperation
  â–¼
RaftNode
  â”‚
  â”‚ 3. Propose to cluster
  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚                     â”‚                     â”‚
  â–¼                     â–¼                     â–¼
Node 1 (Leader)    Node 2 (Follower)   Node 3 (Follower)
  â”‚                     â”‚                     â”‚
  â”‚ 4. Append to log    â”‚ 4. Append to log    â”‚ 4. Append to log
  â”‚                     â”‚                     â”‚
  â”‚ 5. Commit (majority: 2/3)                 â”‚
  â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
  â”‚                     â”‚                     â”‚
  â”‚ 6. Apply to LocalMetadataEngine           â”‚
  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
  â”‚                     â”‚                     â”‚
  â–¼                     â–¼                     â–¼
SurrealKV           SurrealKV           SurrealKV
Ferntree            Ferntree            Ferntree
SurrealMX           SurrealMX           SurrealMX
  â”‚                     â”‚                     â”‚
  â”‚ 7. Return success (after majority commit) â”‚
  â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â”‚
  â”‚ 8. Response to client
  â–¼
Client
```

**å»¶è¿Ÿåˆ†æ**:

- Raft propose: ~1ms
- Network RTT (2 nodes): ~2ms
- Majority commit: ~3ms
- Apply to local engine: ~5ms
- **Total: ~10ms**

#### 2.2 è¯»å–æµç¨‹ (Get Object)

```
Client
  â”‚
  â”‚ 1. GET /bucket/key
  â–¼
ReplicatedMetadataEngine (Any Node)
  â”‚
  â”‚ 2. Read from local replica (no consensus)
  â–¼
LocalMetadataEngine
  â”‚
  â–¼
SurrealKV (Metadata) + SurrealMX (Data)
  â”‚
  â”‚ 3. Return data
  â–¼
Client
```

**ä¼˜åŠ¿**:

- âœ… è¯»å–æ— éœ€å…±è¯†ï¼Œç›´æ¥ä»æœ¬åœ°è¯»
- âœ… å‰¯æœ¬åˆ†æ‹…è¯»è´Ÿè½½
- âœ… å»¶è¿Ÿæä½ï¼ˆ~1msï¼‰

---

## ä¸€è‡´æ€§æ¨¡å‹

### 1. å¼ºä¸€è‡´æ€§ï¼ˆæ¨èï¼‰

**å®ç°**: åŸºäº Raft çº¿æ€§ä¸€è‡´æ€§ä¿è¯

**å†™å…¥è·¯å¾„**:

```
1. Client â†’ Leader
2. Leader proposes to Raft
3. Wait for majority commit (2/3 nodes)
4. Apply to local engine
5. Return success
```

**è¯»å–è·¯å¾„**:

```
Option 1: Read from Leader (å¼ºä¸€è‡´æ€§)
  - ç›´æ¥è¯»å– Leader æœ¬åœ°æ•°æ®
  - ä¿è¯è¯»åˆ°æœ€æ–°å·²æäº¤æ•°æ®

Option 2: Read from Follower (å¼±ä¸€è‡´æ€§)
  - å¯èƒ½è¯»åˆ°ç¨æ—§çš„æ•°æ®
  - å»¶è¿Ÿæä½
  - é€‚åˆå¯å®¹å¿çŸ­æš‚ä¸ä¸€è‡´çš„åœºæ™¯
```

### 2. è¯»å–ä¸€è‡´æ€§çº§åˆ«

```rust
pub enum ReadConsistency {
    /// ä»ä»»æ„å‰¯æœ¬è¯»ï¼ˆæœ€å¿«ï¼Œå¯èƒ½ä¸ä¸€è‡´ï¼‰
    Eventual,

    /// ä» Leader è¯»ï¼ˆå¼ºä¸€è‡´æ€§ï¼‰
    Linearizable,

    /// ä»æœ¬åœ°è¯»ï¼Œä½†å…ˆåŒæ­¥ commit indexï¼ˆæŠ˜ä¸­ï¼‰
    BoundedStaleness { max_staleness_ms: u64 },
}

impl ReplicatedMetadataEngine {
    pub async fn get_object_with_consistency(
        &self,
        bucket: &str,
        key: &str,
        consistency: ReadConsistency,
    ) -> Result<ObjectInfo> {
        match consistency {
            ReadConsistency::Eventual => {
                // ç›´æ¥ä»æœ¬åœ°è¯»
                self.local_engine.get_object(bucket, key, ObjectOptions::default()).await
            }
            ReadConsistency::Linearizable => {
                // ç¡®ä¿è¯»åˆ°æœ€æ–°æ•°æ®
                if !self.raft_node.is_leader() {
                    // Forward to leader
                    return self.forward_to_leader(bucket, key).await;
                }

                // Read from leader
                self.local_engine.get_object(bucket, key, ObjectOptions::default()).await
            }
            ReadConsistency::BoundedStaleness { max_staleness_ms } => {
                // æ£€æŸ¥æœ¬åœ°æ»åç¨‹åº¦
                let staleness = self.raft_node.staleness_ms();
                if staleness > max_staleness_ms {
                    // Wait for catch-up
                    self.raft_node.wait_catchup(max_staleness_ms).await?;
                }

                self.local_engine.get_object(bucket, key, ObjectOptions::default()).await
            }
        }
    }
}
```

---

## å¤åˆ¶åè®®

### 1. Raft å…±è¯†åè®®

**é€‰æ‹©ç†ç”±**:

- âœ… å¼ºä¸€è‡´æ€§ä¿è¯
- âœ… æˆç†Ÿç¨³å®šï¼ˆetcdã€TiKV ä½¿ç”¨ï¼‰
- âœ… Rust ç”Ÿæ€å®Œå–„ï¼ˆ`raft-rs` crateï¼‰
- âœ… æ˜“äºç†è§£å’Œè°ƒè¯•

**æ ¸å¿ƒæ¦‚å¿µ**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Raft Cluster                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Leader    â”‚â”€â”€â”€â–¶â”‚ Follower   â”‚    â”‚ Follower   â”‚  â”‚
â”‚  â”‚  (Node 1)  â”‚â—€â”€â”€â”€â”‚ (Node 2)   â”‚    â”‚ (Node 3)   â”‚  â”‚
â”‚  â”‚            â”‚    â”‚            â”‚    â”‚            â”‚  â”‚
â”‚  â”‚  Term: 5   â”‚    â”‚  Term: 5   â”‚    â”‚  Term: 5   â”‚  â”‚
â”‚  â”‚  Log: [...]â”‚    â”‚  Log: [...]â”‚    â”‚  Log: [...]â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                        â”‚
â”‚  è§’è‰²:                                                  â”‚
â”‚  â€¢ Leader: æ¥æ”¶å®¢æˆ·ç«¯è¯·æ±‚ï¼Œå¤åˆ¶æ—¥å¿—                       â”‚
â”‚  â€¢ Follower: è¢«åŠ¨æ¥æ”¶æ—¥å¿—ï¼Œå‚ä¸æŠ•ç¥¨                      â”‚
â”‚  â€¢ Candidate: é€‰ä¸¾ä¸­çš„å€™é€‰è€…                            â”‚
â”‚                                                        â”‚
â”‚  æ—¥å¿—å¤åˆ¶:                                              â”‚
â”‚  1. Leader æ¥æ”¶æ“ä½œ â†’ Append to local log              â”‚
â”‚  2. Leader â†’ Followers (AppendEntries RPC)            â”‚
â”‚  3. Majority ACK â†’ Commit                             â”‚
â”‚  4. Apply to state machine                            â”‚
â”‚                                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2. æ—¥å¿—ç»“æ„

```rust
pub struct LogEntry {
    /// Log index (monotonic increasing)
    index: u64,

    /// Raft term
    term: u64,

    /// Entry type
    entry_type: EntryType,

    /// Serialized metadata operation
    data: Vec<u8>,

    /// Checksum
    checksum: u32,
}

pub enum EntryType {
    Normal,       // Regular operation
    ConfChange,   // Cluster configuration change
    Snapshot,     // Snapshot marker
}
```

### 3. å¿«ç…§æœºåˆ¶

ä¸ºé¿å…æ—¥å¿—æ— é™å¢é•¿ï¼Œå®šæœŸåˆ›å»ºå¿«ç…§ï¼š

```rust
pub struct MetadataSnapshot {
    /// Snapshot version
    version: u64,

    /// Last included index
    last_index: u64,

    /// Last included term
    last_term: u64,

    /// Full KV store dump
    kv_dump: Vec<u8>,

    /// Index tree dump
    index_dump: Vec<u8>,

    /// Timestamp
    created_at: i64,
}

impl ReplicatedMetadataEngine {
    /// Create snapshot
    pub async fn create_snapshot(&self) -> Result<MetadataSnapshot> {
        // 1. Get current Raft state
        let (last_index, last_term) = self.raft_node.get_applied_state();

        // 2. Export KV store
        let kv_dump = self.export_kv_store().await?;

        // 3. Export index tree
        let index_dump = self.export_index_tree().await?;

        Ok(MetadataSnapshot {
            version: 1,
            last_index,
            last_term,
            kv_dump,
            index_dump,
            created_at: now(),
        })
    }

    /// Apply snapshot
    pub async fn apply_snapshot(&self, snapshot: MetadataSnapshot) -> Result<()> {
        // 1. Clear existing data
        self.local_engine.clear().await?;

        // 2. Import KV store
        self.import_kv_store(&snapshot.kv_dump).await?;

        // 3. Import index tree
        self.import_index_tree(&snapshot.index_dump).await?;

        // 4. Update Raft state
        self.raft_node.set_applied(snapshot.last_index, snapshot.last_term);

        Ok(())
    }
}
```

**è§¦å‘æ¡ä»¶**:

- æ—¥å¿—æ¡ç›®æ•° > 10,000
- æ—¥å¿—å¤§å° > 100MB
- æˆ–æ‰‹åŠ¨è§¦å‘

---

## æ•…éšœå¤„ç†

### 1. èŠ‚ç‚¹æ•…éšœ

#### 1.1 Follower æ•…éšœ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Scenario: Follower Node 2 crashes         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Before:
  Leader (Node 1) â”€â”€â”€ Follower (Node 2) âœ“
                  â””â”€â”€ Follower (Node 3) âœ“

After:
  Leader (Node 1) â”€â”€â”€ Follower (Node 2) âœ— (Down)
                  â””â”€â”€ Follower (Node 3) âœ“

Impact:
  â€¢ Writes still succeed (2/3 majority)
  â€¢ Reads from Node 2 fail â†’ Client retry
  â€¢ System continues normally

Recovery:
  1. Node 2 restarts
  2. Connects to Leader
  3. Catch up missing logs
  4. Resume normal operation
```

#### 1.2 Leader æ•…éšœ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Scenario: Leader Node 1 crashes           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Before:
  Leader (Node 1) âœ“
    â””â”€â”€ Follower (Node 2) âœ“
    â””â”€â”€ Follower (Node 3) âœ“

Failure Detection:
  â€¢ Node 2/3 don't receive heartbeat for election_timeout
  â€¢ Node 2/3 transition to Candidate

Election:
  1. Node 2 â†’ Candidate (Term: 6)
  2. Node 2 requests vote from Node 3
  3. Node 3 grants vote
  4. Node 2 becomes Leader (Term: 6)

After:
  Leader (Node 2) âœ“ (New)
    â””â”€â”€ Follower (Node 1) âœ— (Down)
    â””â”€â”€ Follower (Node 3) âœ“

Recovery Time: < 30s
  â€¢ Election timeout: 150-300ms
  â€¢ Vote request RTT: 10ms
  â€¢ State synchronization: 5-10s
```

#### 1.3 ç½‘ç»œåˆ†åŒº

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Scenario: Network split (1 vs 2 nodes)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Partition:
  Partition A: Node 1 (Leader)
  Partition B: Node 2, Node 3

Behavior:
  â€¢ Partition A (1 node): Cannot achieve majority
    - Writes fail (no quorum)
    - Reads succeed (stale data)
    - Node 1 steps down to Follower
  
  â€¢ Partition B (2 nodes): Can elect new leader
    - Node 2 or 3 becomes new Leader
    - Writes succeed (2/3 majority in B)
    - System continues in Partition B

Healing:
  1. Network partition resolves
  2. Old Leader (Node 1) detects higher term
  3. Node 1 becomes Follower
  4. Node 1 catches up logs from new Leader
  5. Cluster reunified
```

### 2. æ•°æ®æ¢å¤

#### 2.1 æ—¥å¿—å›æ”¾

```rust
impl ReplicatedMetadataEngine {
    /// Recover from crash
    pub async fn recover(&self) -> Result<()> {
        // 1. Load Raft persistent state
        let (hard_state, conf_state) = self.load_raft_state()?;

        // 2. Rebuild Raft node
        let mut raw_node = RawNode::new(
            &self.config.raft_config,
            self.storage.clone(),
            &self.logger,
        )?;

        // 3. Get last applied index
        let last_applied = self.local_engine.get_last_applied_index().await?;

        // 4. Replay uncommitted logs
        for index in (last_applied + 1)..=hard_state.commit {
            let entry = self.storage.get_entry(index)?;
            let op: MetadataOperation = serde_json::from_slice(&entry.data)?;

            self.apply_operation(&op).await?;
        }

        // 5. Resume normal operation
        self.raft_node.set_raw_node(raw_node);

        info!("Metadata engine recovered, last_applied={}", last_applied);
        Ok(())
    }
}
```

#### 2.2 å¿«ç…§æ¢å¤

```rust
impl ReplicatedMetadataEngine {
    /// Install snapshot from Leader
    pub async fn install_snapshot(&self, snapshot: MetadataSnapshot) -> Result<()> {
        info!("Installing snapshot, last_index={}", snapshot.last_index);

        // 1. Validate snapshot
        if !self.validate_snapshot(&snapshot) {
            return Err(Error::CorruptedSnapshot);
        }

        // 2. Stop accepting new requests
        self.state.store(EngineState::Recovering, Ordering::SeqCst);

        // 3. Apply snapshot
        self.apply_snapshot(snapshot).await?;

        // 4. Resume service
        self.state.store(EngineState::Running, Ordering::SeqCst);

        info!("Snapshot installed successfully");
        Ok(())
    }
}
```

### 3. è„‘è£‚é˜²æŠ¤

Raft åè®®å¤©ç„¶é˜²æ­¢è„‘è£‚ï¼š

```
Scenario: Network partition creates 2 groups

Group A: Node 1 (1 node, minority)
  â€¢ Cannot elect Leader (need 2/3 majority)
  â€¢ All writes fail
  â€¢ System safe but unavailable

Group B: Node 2, Node 3 (2 nodes, majority)
  â€¢ Can elect new Leader
  â€¢ Writes succeed
  â€¢ System available

Key: Only one partition can have majority â†’ No dual-leader
```

---

## å®ç°æ–¹æ¡ˆ

### 1. é˜¶æ®µåˆ’åˆ†

#### Phase 1: å¤åˆ¶å±‚æ¡†æ¶ (2 å‘¨)

**ç›®æ ‡**: æ­å»ºåŸºç¡€å¤åˆ¶å±‚ï¼Œä¸å½±å“ç°æœ‰åŠŸèƒ½

```rust
// Step 1: Define replication interfaces
pub trait ReplicationEngine: MetadataEngine {
    fn add_peer(&self, node_id: u64, address: String) -> Result<()>;
    fn remove_peer(&self, node_id: u64) -> Result<()>;
    fn get_replication_status(&self) -> ReplicationStatus;
}

// Step 2: Implement minimal Raft integration
// - Use raft-rs crate
// - Basic log replication
// - Leader election

// Step 3: Wrapper for existing LocalMetadataEngine
pub struct ReplicatedMetadataEngine {
    local: Arc<LocalMetadataEngine>,
    raft: Arc<RaftNode>,
    // ...
}
```

**éªŒè¯**:

- å•èŠ‚ç‚¹æ¨¡å¼æ­£å¸¸å·¥ä½œï¼ˆæ— å›å½’ï¼‰
- Raft èŠ‚ç‚¹èƒ½å¯åŠ¨å’Œé€‰ä¸»
- åŸºæœ¬æ—¥å¿—å¤åˆ¶å·¥ä½œ

#### Phase 2: å†™å…¥å¤åˆ¶ (2 å‘¨)

**ç›®æ ‡**: å®ç°å†™æ“ä½œçš„å¤šå‰¯æœ¬åŒæ­¥

```rust
// Step 1: Serialize write operations
async fn put_object(...) -> Result<ObjectInfo> {
    // 1. Create operation
    let op = MetadataOperation {
        op_type: OperationType::PutObject,
        data: serialize_put_request(...)?,
        ...
    };

    // 2. Propose to Raft
    self.raft.propose(op).await?;

    // 3. Wait for commit
    self.raft.wait_committed(op.op_id).await?;

    // 4. Apply locally
    self.local.put_object(...).await
}

// Step 2: Apply committed operations
async fn apply_operation(op: MetadataOperation) -> Result<()> {
    match op.op_type {
        OperationType::PutObject => { /* apply */ }
        OperationType::DeleteObject => { /* apply */ }
        // ...
    }
}
```

**éªŒè¯**:

- å†™å…¥åˆ° Leader æˆåŠŸå¤åˆ¶åˆ° Followers
- å¤šæ•°ç¡®è®¤åæ‰è¿”å›æˆåŠŸ
- æ•…éšœèŠ‚ç‚¹é‡å¯åèƒ½è¿½èµ¶æ—¥å¿—

#### Phase 3: æ•…éšœè½¬ç§» (1 å‘¨)

**ç›®æ ‡**: å®ç°è‡ªåŠ¨æ•…éšœæ£€æµ‹å’Œ Leader åˆ‡æ¢

```rust
// Step 1: Health monitoring
async fn health_check_loop() {
    loop {
        for peer in peers {
            if !peer.is_healthy() {
                warn!("Peer {} unhealthy", peer.id);
                // Raft handles automatically
            }
        }
        sleep(Duration::from_secs(1)).await;
    }
}

// Step 2: Leader forwarding
async fn handle_request_on_follower(req: Request) -> Result<Response> {
    if self.is_leader() {
        // Process locally
        self.handle_locally(req).await
    } else {
        // Forward to leader
        let leader_addr = self.raft.get_leader_address()?;
        self.forward_to_leader(leader_addr, req).await
    }
}
```

**éªŒè¯**:

- Leader èŠ‚ç‚¹å®•æœºåè‡ªåŠ¨é€‰ä¸»
- å®¢æˆ·ç«¯è¯·æ±‚è‡ªåŠ¨è·¯ç”±åˆ°æ–° Leader
- æ•…éšœè½¬ç§»æ—¶é—´ < 30s

#### Phase 4: å¿«ç…§ä¸å‹ç¼© (1 å‘¨)

**ç›®æ ‡**: å®ç°æ—¥å¿—å‹ç¼©å’Œå¿«ç…§ä¼ è¾“

```rust
// Step 1: Periodic snapshot
async fn snapshot_task() {
    loop {
        sleep(Duration::from_secs(3600)).await; // Every hour

        if self.should_snapshot() {
            let snapshot = self.create_snapshot().await?;
            self.raft.install_snapshot(snapshot).await?;
        }
    }
}

// Step 2: Snapshot transfer
async fn send_snapshot_to_peer(
    peer_id: u64,
    snapshot: MetadataSnapshot,
) -> Result<()> {
    // Stream snapshot in chunks
    let mut stream = snapshot.into_stream();

    while let Some(chunk) = stream.next().await {
        self.send_to_peer(peer_id, chunk).await?;
    }

    Ok(())
}
```

**éªŒè¯**:

- æ—¥å¿—è¾¾åˆ°é˜ˆå€¼æ—¶è‡ªåŠ¨åˆ›å»ºå¿«ç…§
- æ–°èŠ‚ç‚¹åŠ å…¥æ—¶é€šè¿‡å¿«ç…§å¿«é€ŸåŒæ­¥
- å¿«ç…§ä¼ è¾“ä¸å½±å“æ­£å¸¸æœåŠ¡

#### Phase 5: æ€§èƒ½ä¼˜åŒ– (2 å‘¨)

**ç›®æ ‡**: ä¼˜åŒ–å»¶è¿Ÿå’Œååé‡

```rust
// Optimization 1: Batch writes
async fn batch_propose(ops: Vec<MetadataOperation>) -> Result<()> {
    let batch = BatchOperation { ops };
    self.raft.propose(batch).await?;
    self.raft.wait_committed(batch.last_op_id).await?;

    // Apply all in one go
    for op in batch.ops {
        self.apply_operation(op).await?;
    }
    Ok(())
}

// Optimization 2: Pipeline
// Allow multiple in-flight proposals
let mut pending = FuturesUnordered::new();
for op in ops {
pending.push( self .raft.propose(op));
}
while let Some(result) = pending.next().await {
result?;
}

// Optimization 3: Zero-copy
// Avoid serialization/deserialization where possible
```

**éªŒè¯**:

- æ‰¹é‡å†™å…¥ååé‡ > 10,000 ops/s
- P99 å»¶è¿Ÿ < 20ms
- èµ„æºå ç”¨åˆç†ï¼ˆCPU < 20%, Mem < 1GBï¼‰

### 2. é…ç½®ç¤ºä¾‹

```yaml
# rustfs-metadata-replication.yaml

metadata:
  engine_type: replicated  # or "local" for single-node

  replication:
    # Cluster configuration
    nodes:
      - id: 1
        address: "192.168.1.101:7000"
      - id: 2
        address: "192.168.1.102:7000"
      - id: 3
        address: "192.168.1.103:7000"

    # Current node
    node_id: 1

    # Raft configuration
    raft:
      election_timeout_ms: 1000
      heartbeat_interval_ms: 100
      snapshot_interval: 3600  # seconds
      max_log_entries: 10000
      log_dir: "/data/rustfs/raft/log"
      snapshot_dir: "/data/rustfs/raft/snapshot"

    # Consistency
    read_consistency: linearizable  # or "eventual"
    write_quorum: majority          # or "all"

    # Performance
    max_batch_size: 100
    batch_timeout_ms: 10

  # Local engine config (unchanged)
  local:
    kv_path: "/data/rustfs/metadata/kv"
    index_path: "/data/rustfs/metadata/index"
    mx_path: "/data/rustfs/metadata/mx"
```

### 3. API å…¼å®¹æ€§

**ç°æœ‰ API ä¿æŒä¸å˜**:

```rust
// å•èŠ‚ç‚¹æ¨¡å¼
let engine = LocalMetadataEngine::new(...) ?;

// å¤šå‰¯æœ¬æ¨¡å¼ï¼ˆé€æ˜æ›¿æ¢ï¼‰
let engine = ReplicatedMetadataEngine::new(config) ?;

// ç›¸åŒæ¥å£
engine.put_object(bucket, key, reader, size, opts).await?;
engine.get_object_reader(bucket, key, opts).await?;
engine.list_objects(bucket, prefix,...).await?;
```

**æ–°å¢ç®¡ç† API**:

```rust
// é›†ç¾¤ç®¡ç†
engine.add_node(node_id, address) ?;
engine.remove_node(node_id) ?;
engine.transfer_leadership(target_node_id) ?;

// ç›‘æ§
let status = engine.get_replication_status();
println!("Leader: {}", status.leader_id);
println!("Nodes: {:?}", status.nodes);
println!("Lag: {} ops", status.max_lag);

// å¿«ç…§
engine.create_snapshot().await?;
engine.restore_from_snapshot(snapshot_path).await?;
```

---

## æ€§èƒ½ä¼˜åŒ–

### 1. æ‰¹é‡å†™å…¥

```rust
pub struct BatchWriter {
    operations: Vec<MetadataOperation>,
    max_batch_size: usize,
    batch_timeout: Duration,
}

impl BatchWriter {
    pub async fn write(&mut self, op: MetadataOperation) -> Result<()> {
        self.operations.push(op);

        if self.operations.len() >= self.max_batch_size {
            self.flush().await?;
        }

        Ok(())
    }

    async fn flush(&mut self) -> Result<()> {
        if self.operations.is_empty() {
            return Ok(());
        }

        let batch = std::mem::take(&mut self.operations);

        // Single Raft proposal for entire batch
        self.raft.propose_batch(batch).await?;

        Ok(())
    }
}
```

**æ”¶ç›Š**:

- å‡å°‘ Raft ææ¡ˆæ¬¡æ•°
- æé«˜ååé‡ 5-10x
- é™ä½ç½‘ç»œå¼€é”€

### 2. å¹¶è¡Œå¤åˆ¶

```rust
// Leader å¹¶è¡Œå‘é€åˆ°å¤šä¸ª Followers
async fn replicate_to_followers(entry: LogEntry) -> Result<()> {
    let mut futures = Vec::new();

    for follower in self.followers.values() {
        futures.push(follower.send_entry(entry.clone()));
    }

    // Wait for majority
    let mut success_count = 1; // Leader itself
    for result in join_all(futures).await {
        if result.is_ok() {
            success_count += 1;
            if success_count >= self.quorum_size {
                return Ok(()); // Majority achieved
            }
        }
    }

    Err(Error::InsufficientQuorum)
}
```

### 3. è¯»å–ä¼˜åŒ–

```rust
// Read from local replica (no Raft consensus needed)
impl ReplicatedMetadataEngine {
    pub async fn get_object_local(
        &self,
        bucket: &str,
        key: &str,
    ) -> Result<ObjectInfo> {
        // Direct local read, O(1) latency
        self.local_engine.get_object(bucket, key, ObjectOptions::default()).await
    }

    // Read from leader (strong consistency)
    pub async fn get_object_consistent(
        &self,
        bucket: &str,
        key: &str,
    ) -> Result<ObjectInfo> {
        if self.raft_node.is_leader() {
            // Read from leader
            self.local_engine.get_object(bucket, key, ObjectOptions::default()).await
        } else {
            // Forward to leader
            let leader = self.raft_node.get_leader()?;
            self.rpc_client.get_object(&leader, bucket, key).await
        }
    }
}
```

### 4. ç½‘ç»œä¼˜åŒ–

```rust
// gRPC streaming for snapshot transfer
pub async fn stream_snapshot(
    snapshot: MetadataSnapshot,
    mut client: SnapshotClient,
) -> Result<()> {
    const CHUNK_SIZE: usize = 1024 * 1024; // 1MB

    let mut offset = 0;
    while offset < snapshot.data.len() {
        let end = std::cmp::min(offset + CHUNK_SIZE, snapshot.data.len());
        let chunk = &snapshot.data[offset..end];

        client.send_chunk(SnapshotChunk {
            offset,
            data: chunk.to_vec(),
        }).await?;

        offset = end;
    }

    client.finish().await?;
    Ok(())
}
```

---

## è¿ç»´ç®¡ç†

### 1. ç›‘æ§æŒ‡æ ‡

```rust
pub struct ReplicationMetrics {
    // Cluster health
    pub leader_id: u64,
    pub node_count: usize,
    pub healthy_nodes: usize,

    // Performance
    pub write_latency_p50: Duration,
    pub write_latency_p99: Duration,
    pub read_latency_p50: Duration,
    pub throughput_ops_per_sec: f64,

    // Replication lag
    pub max_lag_entries: u64,
    pub max_lag_time_ms: u64,

    // Raft state
    pub current_term: u64,
    pub committed_index: u64,
    pub applied_index: u64,
    pub snapshot_index: u64,

    // Resource usage
    pub log_size_bytes: u64,
    pub snapshot_size_bytes: u64,
    pub memory_usage_bytes: u64,
}

impl ReplicatedMetadataEngine {
    pub fn metrics(&self) -> ReplicationMetrics {
        // Collect and return metrics
    }
}
```

**Prometheus å¯¼å‡º**:

```rust
use prometheus::{register_gauge, register_histogram, Gauge, Histogram};

lazy_static! {
    static ref WRITE_LATENCY: Histogram = register_histogram!(
        "rustfs_metadata_write_latency_seconds",
        "Write operation latency"
    ).unwrap();
    
    static ref REPLICATION_LAG: Gauge = register_gauge!(
        "rustfs_metadata_replication_lag_entries",
        "Number of log entries behind leader"
    ).unwrap();
}
```

### 2. è¿ç»´å‘½ä»¤

```bash
# æŸ¥çœ‹é›†ç¾¤çŠ¶æ€
rustfs-admin metadata status

# æ·»åŠ èŠ‚ç‚¹
rustfs-admin metadata add-node --id 4 --address 192.168.1.104:7000

# ç§»é™¤èŠ‚ç‚¹
rustfs-admin metadata remove-node --id 4

# è½¬ç§» Leader
rustfs-admin metadata transfer-leadership --to 2

# åˆ›å»ºå¿«ç…§
rustfs-admin metadata snapshot create

# æ¢å¤å¿«ç…§
rustfs-admin metadata snapshot restore --path /backup/snapshot-20260224.snap

# æŸ¥çœ‹å¤åˆ¶å»¶è¿Ÿ
rustfs-admin metadata lag
```

### 3. å‘Šè­¦è§„åˆ™

```yaml
# Prometheus alerting rules

groups:
  - name: rustfs_metadata_replication
    rules:
      # No leader elected
      - alert: MetadataNoLeader
        expr: rustfs_metadata_has_leader == 0
        for: 30s
        annotations:
          summary: "No metadata leader elected"

      # High replication lag
      - alert: MetadataHighLag
        expr: rustfs_metadata_replication_lag_entries > 1000
        for: 1m
        annotations:
          summary: "Metadata replication lag > 1000 entries"

      # Node down
      - alert: MetadataNodeDown
        expr: up{job="rustfs-metadata"} == 0
        for: 30s
        annotations:
          summary: "Metadata node {{ $labels.instance }} is down"

      # High write latency
      - alert: MetadataHighWriteLatency
        expr: histogram_quantile(0.99, rustfs_metadata_write_latency_seconds) > 0.1
        for: 5m
        annotations:
          summary: "Metadata write P99 latency > 100ms"
```

---

## æ€»ç»“

### ä¼˜åŠ¿

1. **é«˜å¯ç”¨æ€§**
    - å¤šå‰¯æœ¬å®¹é”™ï¼ˆ3 å‰¯æœ¬å®¹å¿ 1 ä¸ªæ•…éšœï¼‰
    - è‡ªåŠ¨æ•…éšœè½¬ç§»ï¼ˆ< 30sï¼‰
    - æ— å•ç‚¹æ•…éšœ

2. **æ•°æ®å®‰å…¨**
    - å¤šèŠ‚ç‚¹æŒä¹…åŒ–
    - Raft ä¿è¯å·²æäº¤æ•°æ®ä¸ä¸¢å¤±
    - å¿«ç…§å¤‡ä»½å’Œæ¢å¤

3. **æ€§èƒ½æ‰©å±•**
    - å‰¯æœ¬åˆ†æ‹…è¯»è´Ÿè½½
    - å†™å…¥æ€§èƒ½åŸºæœ¬ä¸å˜ï¼ˆ~10msï¼‰
    - è¯»å–å»¶è¿Ÿæä½ï¼ˆ~1ms æœ¬åœ°è¯»ï¼‰

4. **è¿ç»´å‹å¥½**
    - åœ¨çº¿æ·»åŠ /åˆ é™¤èŠ‚ç‚¹
    - ç°åº¦å‡çº§æ”¯æŒ
    - ä¸°å¯Œçš„ç›‘æ§æŒ‡æ ‡

### æŒ‘æˆ˜

1. **å¤æ‚åº¦å¢åŠ **
    - Raft åè®®å­¦ä¹ æ›²çº¿
    - åˆ†å¸ƒå¼è°ƒè¯•å›°éš¾
    - éœ€è¦æ›´å¤šæµ‹è¯•è¦†ç›–

2. **èµ„æºå¼€é”€**
    - æ¯ä¸ªèŠ‚ç‚¹éœ€è¦å®Œæ•´æ•°æ®å‰¯æœ¬
    - ç½‘ç»œå¸¦å®½å ç”¨å¢åŠ 
    - æ—¥å¿—å’Œå¿«ç…§å­˜å‚¨

3. **è¿ç»´æˆæœ¬**
    - éœ€è¦è‡³å°‘ 3 ä¸ªèŠ‚ç‚¹
    - ç›‘æ§å’Œå‘Šè­¦é…ç½®
    - æ•…éšœæ’æŸ¥éš¾åº¦å¢åŠ 

### åç»­è§„åˆ’

**çŸ­æœŸ (3 ä¸ªæœˆ)**:

- âœ… å®ç°åŸºç¡€å¤åˆ¶æ¡†æ¶
- âœ… å®Œæˆå†™å…¥å¤åˆ¶å’Œæ•…éšœè½¬ç§»
- âœ… ç”Ÿäº§ç¯å¢ƒå°è§„æ¨¡è¯•ç‚¹

**ä¸­æœŸ (6 ä¸ªæœˆ)**:

- ğŸ”„ ä¼˜åŒ–æ€§èƒ½å’Œèµ„æºå ç”¨
- ğŸ”„ å®Œå–„ç›‘æ§å’Œè¿ç»´å·¥å…·
- ğŸ”„ å¤§è§„æ¨¡ç”Ÿäº§éªŒè¯

**é•¿æœŸ (1 å¹´)**:

- ğŸ’¡ è·¨æ•°æ®ä¸­å¿ƒå¤åˆ¶
- ğŸ’¡ æ™ºèƒ½è´Ÿè½½å‡è¡¡
- ğŸ’¡ è‡ªåŠ¨æ‰©ç¼©å®¹

---

**ä½œè€…**: RustFS Architecture Team  
**å®¡æ ¸**: [å¾…å®¡æ ¸]  
**ç‰ˆæœ¬**: 1.0  
**æ›´æ–°æ—¥æœŸ**: 2026-02-24

