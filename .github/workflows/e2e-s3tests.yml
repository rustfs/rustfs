name: e2e-s3tests

on:
  workflow_dispatch:
    inputs:
      test-mode:
        description: "Test mode to run"
        required: true
        type: choice
        default: "single"
        options:
          - single
          - multi

env:
  S3_ACCESS_KEY: rustfsadmin
  S3_SECRET_KEY: rustfsadmin
  RUST_LOG: info
  PLATFORM: linux/amd64

defaults:
  run:
    shell: bash

jobs:
  s3tests-single:
    if: github.event.inputs.test-mode == 'single'
    runs-on: ubuntu-latest
    timeout-minutes: 120
    steps:
      - uses: actions/checkout@v4

      - name: Enable buildx
        uses: docker/setup-buildx-action@v3

      - name: Build RustFS image (source)
        run: |
          DOCKER_BUILDKIT=1 docker buildx build --load \
            --platform ${PLATFORM} \
            -t rustfs-ci \
            -f Dockerfile.source .

      - name: Create network
        run: docker network inspect rustfs-net >/dev/null 2>&1 || docker network create rustfs-net

      - name: Remove existing rustfs-single (if any)
        run: docker rm -f rustfs-single >/dev/null 2>&1 || true

      - name: Start single RustFS
        run: |
          docker run -d --name rustfs-single \
            --network rustfs-net \
            -e RUSTFS_ADDRESS=0.0.0.0:9000 \
            -e RUSTFS_ACCESS_KEY=$S3_ACCESS_KEY \
            -e RUSTFS_SECRET_KEY=$S3_SECRET_KEY \
            -e RUSTFS_VOLUMES="/data/rustfs0 /data/rustfs1 /data/rustfs2 /data/rustfs3" \
            -v /tmp/rustfs-single:/data \
            rustfs-ci

      - name: Wait for RustFS ready
        run: |
          for i in {1..30}; do
            if docker run --rm --network rustfs-net curlimages/curl:latest \
              -sf http://rustfs-single:9000/health >/dev/null 2>&1; then
              echo "RustFS is ready"
              exit 0
            fi

            if [ "$(docker inspect -f '{{.State.Running}}' rustfs-single 2>/dev/null)" != "true" ]; then
              echo "RustFS container not running" >&2
              docker logs rustfs-single || true
              exit 1
            fi
            sleep 2
          done

          echo "Health check failed; container is running, proceeding with caution" >&2
          docker logs rustfs-single || true

      - name: Generate s3tests config
        run: |
          export S3_HOST=rustfs-single
          envsubst < .github/s3tests/s3tests.conf > s3tests.conf
          echo "Generated s3tests.conf:"
          cat s3tests.conf

      - name: Run ceph s3-tests (S3-compatible subset)
        run: |
          mkdir -p artifacts/s3tests-single
          
          # Run tests inside a Docker container on the same network as RustFS
          # This fixes DNS resolution issues and allows proper connectivity
          docker run --rm \
            --network rustfs-net \
            -v ${GITHUB_WORKSPACE}/s3tests.conf:/etc/s3tests.conf:ro \
            -v ${GITHUB_WORKSPACE}/artifacts/s3tests-single:/artifacts \
            -w /s3-tests \
            --platform ${PLATFORM} \
            python:3.12-slim \
            bash -c '
              set -e
              echo "Installing dependencies..."
              apt-get update -qq && apt-get install -y -qq git > /dev/null 2>&1
              git clone --depth 1 https://github.com/ceph/s3-tests.git /s3-tests
              cd /s3-tests
              pip install -q --no-cache-dir -r requirements.txt pytest-xdist
              
              echo "Running S3 compatibility tests..."
              # Use pytest directly with parallel execution (-n auto)
              # Filter out unsupported features using markers
              S3TEST_CONF=/etc/s3tests.conf pytest \
                -v \
                --tb=short \
                -n 4 \
                --dist=loadgroup \
                --maxfail=50 \
                --junitxml=/artifacts/junit.xml \
                s3tests/functional/test_s3.py \
                -m "not lifecycle and not versioning and not s3website and not bucket_logging and not encryption and not sse_s3 and not cloud_transition and not cloud_restore and not lifecycle_expiration and not lifecycle_transition"
            '

      - name: Upload artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: s3tests-single
          path: artifacts/s3tests-single/**

  s3tests-multi:
    if: github.event.inputs.test-mode == 'multi'
    runs-on: ubuntu-latest
    timeout-minutes: 120
    steps:
      - uses: actions/checkout@v4

      - name: Enable buildx
        uses: docker/setup-buildx-action@v3

      - name: Build RustFS image (source)
        run: |
          DOCKER_BUILDKIT=1 docker buildx build --load \
            --platform ${PLATFORM} \
            -t rustfs-ci \
            -f Dockerfile.source .

      - name: Prepare cluster compose
        run: |
          cat > compose.yml <<'EOF'
          services:
            rustfs1:
              image: rustfs-ci
              hostname: rustfs1
              networks: [rustfs-net]
              environment:
                RUSTFS_ADDRESS: "0.0.0.0:9000"
                RUSTFS_ACCESS_KEY: ${S3_ACCESS_KEY}
                RUSTFS_SECRET_KEY: ${S3_SECRET_KEY}
                RUSTFS_VOLUMES: "/data/rustfs0 /data/rustfs1 /data/rustfs2 /data/rustfs3"
              volumes:
                - rustfs1-data:/data
            rustfs2:
              image: rustfs-ci
              hostname: rustfs2
              networks: [rustfs-net]
              environment:
                RUSTFS_ADDRESS: "0.0.0.0:9000"
                RUSTFS_ACCESS_KEY: ${S3_ACCESS_KEY}
                RUSTFS_SECRET_KEY: ${S3_SECRET_KEY}
                RUSTFS_VOLUMES: "/data/rustfs0 /data/rustfs1 /data/rustfs2 /data/rustfs3"
              volumes:
                - rustfs2-data:/data
            rustfs3:
              image: rustfs-ci
              hostname: rustfs3
              networks: [rustfs-net]
              environment:
                RUSTFS_ADDRESS: "0.0.0.0:9000"
                RUSTFS_ACCESS_KEY: ${S3_ACCESS_KEY}
                RUSTFS_SECRET_KEY: ${S3_SECRET_KEY}
                RUSTFS_VOLUMES: "/data/rustfs0 /data/rustfs1 /data/rustfs2 /data/rustfs3"
              volumes:
                - rustfs3-data:/data
            rustfs4:
              image: rustfs-ci
              hostname: rustfs4
              networks: [rustfs-net]
              environment:
                RUSTFS_ADDRESS: "0.0.0.0:9000"
                RUSTFS_ACCESS_KEY: ${S3_ACCESS_KEY}
                RUSTFS_SECRET_KEY: ${S3_SECRET_KEY}
                RUSTFS_VOLUMES: "/data/rustfs0 /data/rustfs1 /data/rustfs2 /data/rustfs3"
              volumes:
                - rustfs4-data:/data
            lb:
              image: haproxy:2.9
              hostname: lb
              networks: [rustfs-net]
              ports:
                - "9000:9000"
              volumes:
                - ./haproxy.cfg:/usr/local/etc/haproxy/haproxy.cfg:ro
          networks:
            rustfs-net:
              name: rustfs-net
          volumes:
            rustfs1-data:
            rustfs2-data:
            rustfs3-data:
            rustfs4-data:
          EOF

          cat > haproxy.cfg <<'EOF'
          defaults
            mode http
            timeout connect 5s
            timeout client  30s
            timeout server  30s

          frontend fe_s3
            bind *:9000
            default_backend be_s3

          backend be_s3
            balance roundrobin
            server s1 rustfs1:9000 check
            server s2 rustfs2:9000 check
            server s3 rustfs3:9000 check
            server s4 rustfs4:9000 check
          EOF

      - name: Launch cluster
        run: docker compose -f compose.yml up -d

      - name: Wait for LB ready
        run: |
          for i in {1..60}; do
            if docker run --rm --network rustfs-net curlimages/curl \
              -sf http://lb:9000/health >/dev/null 2>&1; then
              echo "Load balancer is ready"
              exit 0
            fi
            sleep 2
          done
          echo "LB or backend not ready" >&2
          docker compose -f compose.yml logs --tail=200 || true
          exit 1

      - name: Generate s3tests config
        run: |
          export S3_HOST=lb
          envsubst < .github/s3tests/s3tests.conf > s3tests.conf
          echo "Generated s3tests.conf:"
          cat s3tests.conf

      - name: Run ceph s3-tests (multi, S3-compatible subset)
        run: |
          mkdir -p artifacts/s3tests-multi
          
          # Run tests inside a Docker container on the same network as the cluster
          docker run --rm \
            --network rustfs-net \
            -v ${GITHUB_WORKSPACE}/s3tests.conf:/etc/s3tests.conf:ro \
            -v ${GITHUB_WORKSPACE}/artifacts/s3tests-multi:/artifacts \
            -w /s3-tests \
            --platform ${PLATFORM} \
            python:3.12-slim \
            bash -c '
              set -e
              echo "Installing dependencies..."
              apt-get update -qq && apt-get install -y -qq git > /dev/null 2>&1
              git clone --depth 1 https://github.com/ceph/s3-tests.git /s3-tests
              cd /s3-tests
              pip install -q --no-cache-dir -r requirements.txt pytest-xdist
              
              echo "Running S3 compatibility tests against multi-node cluster..."
              # Use pytest directly with parallel execution
              # Filter out unsupported features using markers
              S3TEST_CONF=/etc/s3tests.conf pytest \
                -v \
                --tb=short \
                -n 4 \
                --dist=loadgroup \
                --maxfail=50 \
                --junitxml=/artifacts/junit.xml \
                s3tests/functional/test_s3.py \
                -m "not lifecycle and not versioning and not s3website and not bucket_logging and not encryption and not sse_s3 and not cloud_transition and not cloud_restore and not lifecycle_expiration and not lifecycle_transition"
            '

      - name: Upload artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: s3tests-multi
          path: artifacts/s3tests-multi/**
